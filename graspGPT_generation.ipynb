{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraspGPT 模型推理与生成\n",
    "\n",
    "本notebook用于从checkpoint加载GraspGPT模型，加载sequence序列数据，并进行token生成预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库和模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-29 18:51:22,931] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wuminye/miniconda3/envs/grasp/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/wuminye/miniconda3/envs/grasp/compiler_compat/ld: cannot find -lcufile: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-29 18:51:25,495] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "模块导入完成\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import deepspeed\n",
    "from deepspeed import comm as dist\n",
    "\n",
    "# 设置路径并导入graspGPT模块\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(current_dir)\n",
    "sys.path.append(os.path.join(current_dir, 'graspGPT'))\n",
    "\n",
    "from graspGPT.model.model import graspGPT\n",
    "from graspGPT.model.utils import CfgNode as CN\n",
    "from graspGPT.model.token_manager import get_token_manager, decode_sequence, encode_sequence\n",
    "from graspGPT.model.parser_and_serializer import Serializer, Parser,Seq\n",
    "from graspGPT.model.core import generate_amodal_sequence\n",
    "import random\n",
    "\n",
    "print(\"模块导入完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint路径: output/checkpoints/amodal\n",
      "序列文件路径: output/scene_0000_objects_merged_aligned_seq.pth\n",
      "生成参数: max_new_tokens=2000, temperature=0.3\n"
     ]
    }
   ],
   "source": [
    "# 设置参数\n",
    "checkpoint_path = \"output/checkpoints/amodal\"  # 修改为实际的checkpoint路径\n",
    "sequence_file = \"output/scene_0000_objects_merged_aligned_seq.pth\"  # 修改为align_coords.py生成的pth文件路径\n",
    "deepspeed_config_path = \"deepspeed_config.json\"  # DeepSpeed配置文件路径\n",
    "\n",
    "# 生成参数\n",
    "max_new_tokens = 2000\n",
    "temperature = 0.3\n",
    "do_sample = True\n",
    "top_k = None\n",
    "num_sequences = 1\n",
    "seed = 42\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "print(f\"Checkpoint路径: {checkpoint_path}\")\n",
    "print(f\"序列文件路径: {sequence_file}\")\n",
    "print(f\"生成参数: max_new_tokens={max_new_tokens}, temperature={temperature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 辅助函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "辅助函数定义完成\n"
     ]
    }
   ],
   "source": [
    "def parse_config_string(config_str):\n",
    "    \"\"\"解析字符串格式的配置到字典\"\"\"\n",
    "    config_dict = {}\n",
    "    for line in config_str.strip().split('\\n'):\n",
    "        if ':' in line:\n",
    "            key, value = line.split(':', 1)\n",
    "            key = key.strip()\n",
    "            value = value.strip()\n",
    "            \n",
    "            # 尝试解析值\n",
    "            try:\n",
    "                if value.lower() == 'true':\n",
    "                    value = True\n",
    "                elif value.lower() == 'false':\n",
    "                    value = False\n",
    "                elif value.lower() == 'none':\n",
    "                    value = None\n",
    "                elif value.startswith('(') and value.endswith(')'):\n",
    "                    value = eval(value)\n",
    "                elif value.startswith('[') and value.endswith(']'):\n",
    "                    value = eval(value)\n",
    "                elif '.' in value:\n",
    "                    try:\n",
    "                        value = float(value)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                else:\n",
    "                    try:\n",
    "                        value = int(value)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            config_dict[key] = value\n",
    "    \n",
    "    return config_dict\n",
    "\n",
    "def load_training_config(checkpoint_dir):\n",
    "    \"\"\"从checkpoint目录加载训练配置\"\"\"\n",
    "    # 尝试从training_state.json加载配置\n",
    "    training_state_path = os.path.join(checkpoint_dir, 'training_state.json')\n",
    "    if os.path.exists(training_state_path):\n",
    "        with open(training_state_path, 'r') as f:\n",
    "            training_state = json.load(f)\n",
    "            if 'config' in training_state:\n",
    "                config_data = training_state['config']\n",
    "                \n",
    "                if isinstance(config_data, dict):\n",
    "                    parsed_config = {}\n",
    "                    for section_name, section_value in config_data.items():\n",
    "                        if isinstance(section_value, str):\n",
    "                            parsed_config[section_name] = parse_config_string(section_value)\n",
    "                        else:\n",
    "                            parsed_config[section_name] = section_value\n",
    "                    return CN.from_dict(parsed_config)\n",
    "                else:\n",
    "                    return CN.from_dict(config_data)\n",
    "    \n",
    "    # 备用：查找config.json文件\n",
    "    search_dirs = [checkpoint_dir, os.path.dirname(checkpoint_dir)]\n",
    "    config_names = ['config.json', 'training_config.json']\n",
    "    \n",
    "    for search_dir in search_dirs:\n",
    "        for config_name in config_names:\n",
    "            config_path = os.path.join(search_dir, config_name)\n",
    "            if os.path.exists(config_path):\n",
    "                with open(config_path, 'r') as f:\n",
    "                    config_dict = json.load(f)\n",
    "                return CN.from_dict(config_dict)\n",
    "    \n",
    "    raise FileNotFoundError(f\"未找到配置文件在 {checkpoint_dir} 或其父目录中\")\n",
    "\n",
    "print(\"辅助函数定义完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 第一部分：从checkpoint目录加载模型和参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载训练配置...\n",
      "训练配置加载成功\n",
      "模型类型: gpt2\n",
      "词汇大小: 147219\n",
      "块大小: 6000\n"
     ]
    }
   ],
   "source": [
    "# 加载训练配置\n",
    "print(\"正在加载训练配置...\")\n",
    "config = load_training_config(checkpoint_path)\n",
    "print(\"训练配置加载成功\")\n",
    "\n",
    "# 打印模型配置信息\n",
    "print(f\"模型类型: {getattr(config.model, 'model_type', 'custom')}\")\n",
    "print(f\"词汇大小: {config.model.vocab_size}\")\n",
    "print(f\"块大小: {config.model.block_size}\")\n",
    "\n",
    "# 修复模型配置以满足XOR条件\n",
    "if hasattr(config.model, 'model_type') and config.model.model_type:\n",
    "    if hasattr(config.model, 'n_layer'):\n",
    "        config.model.n_layer = None\n",
    "    if hasattr(config.model, 'n_head'):\n",
    "        config.model.n_head = None  \n",
    "    if hasattr(config.model, 'n_embd'):\n",
    "        config.model.n_embd = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在获取token管理器...\n",
      "从样本文件获取体积维度: precomputed_batch_63938_0.pth\n",
      "Token管理器词汇大小: 147219\n",
      "使用的体积维度: 80x54x34\n"
     ]
    }
   ],
   "source": [
    "# 获取token管理器和词汇表\n",
    "print(\"正在获取token管理器...\")\n",
    "token_manager = get_token_manager()\n",
    "\n",
    "# 生成token映射\n",
    "img_h, img_w, img_d =80, 54, 34  # 默认体积维度\n",
    "config.dataset.data_path = 'output/precomputed_data/'\n",
    "# 尝试从数据中获取实际维度\n",
    "if hasattr(config.dataset, 'data_path') and config.dataset.data_path:\n",
    "    import glob\n",
    "    data_files = glob.glob(os.path.join(config.dataset.data_path, \"*.pth\"))\n",
    "    if data_files:\n",
    "        sample_file = data_files[0]\n",
    "        print(f\"从样本文件获取体积维度: {os.path.basename(sample_file)}\")\n",
    "        raw_data = torch.load(sample_file, weights_only=False)\n",
    "        if 'volume_dims' in raw_data:\n",
    "            img_h, img_w, img_d = raw_data['volume_dims']\n",
    "            print(f\"从数据获取的体积维度: {img_h}x{img_w}x{img_d}\")\n",
    "\n",
    "token_mapping = token_manager.generate_mapping(img_h, img_w, img_d)\n",
    "vocab_size = len(token_mapping)\n",
    "\n",
    "# 更新配置中的词汇大小\n",
    "config.model.vocab_size = vocab_size\n",
    "\n",
    "print(f\"Token管理器词汇大小: {vocab_size}\")\n",
    "print(f\"使用的体积维度: {img_h}x{img_w}x{img_d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在创建模型...\n",
      "Using Qwen2 model with RoPE position encoding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 226.36M\n",
      "模型创建完成: 226.36M 参数\n",
      "正在加载DeepSpeed配置...\n",
      "bf16已启用用于推理\n",
      "DeepSpeed配置加载完成\n"
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "print(\"正在创建模型...\")\n",
    "model = graspGPT(config.model)\n",
    "param_count = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "print(f\"模型创建完成: {param_count:.2f}M 参数\")\n",
    "\n",
    "# 加载DeepSpeed配置\n",
    "print(\"正在加载DeepSpeed配置...\")\n",
    "with open(deepspeed_config_path, 'r') as f:\n",
    "    ds_config = json.load(f)\n",
    "\n",
    "# 配置推理模式\n",
    "ds_config.update({\n",
    "    \"train_batch_size\": 1,\n",
    "    \"train_micro_batch_size_per_gpu\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "})\n",
    "\n",
    "if ds_config.get(\"bf16\", {}).get(\"enabled\", False):\n",
    "    print(\"bf16已启用用于推理\")\n",
    "\n",
    "print(\"DeepSpeed配置加载完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载checkpoint: output/checkpoints/amodal\n",
      "[2025-09-29 18:51:29,553] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.5, git-hash=unknown, git-branch=unknown\n",
      "[2025-09-29 18:51:29,553] [INFO] [comm.py:821:init_distributed] cdb=None\n",
      "[2025-09-29 18:51:29,554] [INFO] [comm.py:836:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2025-09-29 18:51:29,892] [INFO] [comm.py:891:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.24.93.140, master_port=29500\n",
      "[2025-09-29 18:51:29,893] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-09-29 18:51:29,935] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 1\n",
      "[2025-09-29 18:51:30,210] [INFO] [engine.py:1356:_configure_distributed_model] ********** distributed groups summary **********\n",
      "\t self.dp_world_size=1\n",
      "\t self.mp_world_size=1\n",
      "\t self.seq_dp_world_size=1\n",
      "\t self.sequence_parallel_size=1\n",
      "***********************************************\n",
      "[2025-09-29 18:51:30,338] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/wuminye/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/wuminye/.cache/torch_extensions/py310_cu118/fused_adam/build.ninja...\n",
      "/home/wuminye/miniconda3/envs/grasp/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load fused_adam op: 0.018658876419067383 seconds\n",
      "[2025-09-29 18:51:30,370] [INFO] [logging.py:107:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2025-09-29 18:51:30,370] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-09-29 18:51:30,373] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam\n",
      "[2025-09-29 18:51:30,373] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>\n",
      "[2025-09-29 18:51:30,374] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 1 optimizer\n",
      "[2025-09-29 18:51:30,375] [INFO] [stage_1_and_2.py:178:__init__] Reduce bucket size 500000000\n",
      "[2025-09-29 18:51:30,375] [INFO] [stage_1_and_2.py:179:__init__] Allgather bucket size 500000000\n",
      "[2025-09-29 18:51:30,376] [INFO] [stage_1_and_2.py:180:__init__] CPU Offload: False\n",
      "[2025-09-29 18:51:30,376] [INFO] [stage_1_and_2.py:181:__init__] Round robin gradient partitioning: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module fused_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-29 18:51:30,751] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
      "[2025-09-29 18:51:30,752] [INFO] [utils.py:782:see_memory_usage] MA 1.27 GB         Max_MA 1.69 GB         CA 1.69 GB         Max_CA 2 GB \n",
      "[2025-09-29 18:51:30,753] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 3.38 GB, percent = 13.8%\n",
      "[2025-09-29 18:51:30,887] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
      "[2025-09-29 18:51:30,888] [INFO] [utils.py:782:see_memory_usage] MA 1.27 GB         Max_MA 2.11 GB         CA 2.53 GB         Max_CA 3 GB \n",
      "[2025-09-29 18:51:30,888] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 3.38 GB, percent = 13.8%\n",
      "[2025-09-29 18:51:30,889] [INFO] [stage_1_and_2.py:605:__init__] optimizer state initialized\n",
      "[2025-09-29 18:51:30,997] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-09-29 18:51:30,998] [INFO] [utils.py:782:see_memory_usage] MA 1.27 GB         Max_MA 1.27 GB         CA 2.53 GB         Max_CA 3 GB \n",
      "[2025-09-29 18:51:30,998] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 3.38 GB, percent = 13.8%\n",
      "[2025-09-29 18:51:31,000] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
      "DeepSpeed加载失败: unsupported operand type(s) for -: 'str' and 'str'\n",
      "回退到PyTorch加载...\n",
      "使用PyTorch从以下位置加载checkpoint: output/checkpoints/amodal/mp_rank_00_model_states.pt\n",
      "使用PyTorch成功加载checkpoint\n",
      "模型加载完成！\n"
     ]
    }
   ],
   "source": [
    "# 加载checkpoint\n",
    "print(f\"正在加载checkpoint: {checkpoint_path}\")\n",
    "\n",
    "# 解析checkpoint路径\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    parent_dir = os.path.dirname(checkpoint_path)\n",
    "    tag = os.path.basename(checkpoint_path)\n",
    "elif os.path.isdir(checkpoint_path):\n",
    "    parent_dir = os.path.dirname(checkpoint_path)\n",
    "    tag = os.path.basename(checkpoint_path)\n",
    "else:\n",
    "    raise ValueError(f\"Checkpoint路径不存在: {checkpoint_path}\")\n",
    "\n",
    "# 尝试使用DeepSpeed加载\n",
    "try:\n",
    "    # 初始化DeepSpeed引擎用于推理\n",
    "    model_engine, _, _, _ = deepspeed.initialize(\n",
    "        model=model,\n",
    "        config=ds_config,\n",
    "        model_parameters=model.parameters()\n",
    "    )\n",
    "    \n",
    "    # 加载checkpoint\n",
    "    _, client_state = model_engine.load_checkpoint(parent_dir, tag=tag)\n",
    "    print(f\"使用DeepSpeed成功加载checkpoint\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"DeepSpeed加载失败: {e}\")\n",
    "    print(\"回退到PyTorch加载...\")\n",
    "    \n",
    "    # 回退：使用常规PyTorch加载\n",
    "    checkpoint_file = os.path.join(checkpoint_path, 'mp_rank_00_model_states.pt')\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        print(f\"使用PyTorch从以下位置加载checkpoint: {checkpoint_file}\")\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "        \n",
    "        state_dict = checkpoint.get('module', checkpoint)\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "        \n",
    "        print(f\"使用PyTorch成功加载checkpoint\")\n",
    "        \n",
    "        # 创建模型包装器以兼容DeepSpeed接口\n",
    "        class ModelWrapper:\n",
    "            def __init__(self, model):\n",
    "                self.module = model\n",
    "                self.model = model\n",
    "                self.local_rank = 0\n",
    "                \n",
    "            def eval(self):\n",
    "                self.module.eval()\n",
    "                \n",
    "            def __call__(self, *args, **kwargs):\n",
    "                return self.module(*args, **kwargs)\n",
    "        \n",
    "        model_engine = ModelWrapper(model)\n",
    "    else:\n",
    "        raise ValueError(f\"找不到checkpoint文件: {checkpoint_file}\")\n",
    "\n",
    "print(\"模型加载完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 第二部分：从外部pth文件加载sequence序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载序列数据: output/scene_0000_objects_merged_aligned_seq.pth\n",
      "序列数据键: ['seq', 'token_sequence', 'data_list', 'volume_dims', 'voxel_size', 'bbox_min', 'bbox_max', 'scene_name']\n",
      "使用键 'seq' 作为token序列\n"
     ]
    }
   ],
   "source": [
    "# 加载序列数据\n",
    "print(f\"正在加载序列数据: {sequence_file}\")\n",
    "\n",
    "if not os.path.exists(sequence_file):\n",
    "    raise FileNotFoundError(f\"序列文件不存在: {sequence_file}\")\n",
    "\n",
    "# 加载序列数据\n",
    "sequence_data = torch.load(sequence_file, weights_only=False)\n",
    "\n",
    "# 检查数据结构\n",
    "print(f\"序列数据键: {list(sequence_data.keys()) if isinstance(sequence_data, dict) else 'not a dict'}\")\n",
    "\n",
    "# 提取token序列\n",
    "if isinstance(sequence_data, dict):\n",
    "    if 'tokens' in sequence_data:\n",
    "        token_sequence = sequence_data['tokens']\n",
    "    elif 'sequence' in sequence_data:\n",
    "        token_sequence = sequence_data['sequence']\n",
    "    elif 'token_ids' in sequence_data:\n",
    "        token_sequence = sequence_data['token_ids']\n",
    "    else:\n",
    "        # 假设第一个可用的键包含序列\n",
    "        key = list(sequence_data.keys())[0]\n",
    "        token_sequence = sequence_data[key]\n",
    "        print(f\"使用键 '{key}' 作为token序列\")\n",
    "elif isinstance(sequence_data, (list, tuple)):\n",
    "    token_sequence = sequence_data\n",
    "else:\n",
    "    token_sequence = sequence_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------(training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载序列数据: output/precomputed_data/precomputed_batch_63938_0.pth\n",
      "序列数据键: not a dict\n",
      "使用键 raw_tokens 作为token序列\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sequence_file = 'output/precomputed_data/precomputed_batch_63938_0.pth'\n",
    "# 加载序列数据\n",
    "print(f\"正在加载序列数据: {sequence_file}\")\n",
    "\n",
    "if not os.path.exists(sequence_file):\n",
    "    raise FileNotFoundError(f\"序列文件不存在: {sequence_file}\")\n",
    "\n",
    "# 加载序列数据\n",
    "sequence_data = torch.load(sequence_file, weights_only=False)\n",
    "\n",
    "sequence_data = sequence_data[5]['raw_tokens']\n",
    "\n",
    "# 检查数据结构\n",
    "print(f\"序列数据键: {list(sequence_data.keys()) if isinstance(sequence_data, dict) else 'not a dict'}\")\n",
    "\n",
    "\n",
    "print(f\"使用键 raw_tokens 作为token序列\")\n",
    "\n",
    "token_sequence = decode_sequence(sequence_data, token_mapping)\n",
    "parser = Parser(token_sequence)\n",
    "token_sequence = parser.parse()\n",
    "print(len(token_sequence.items))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造场景数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object13 object40\n"
     ]
    }
   ],
   "source": [
    "sbs= token_sequence.items\n",
    "#random.shuffle(sbs)\n",
    "sbs[0].sbs = sbs[0].sbs[:3]\n",
    "New_seq = Seq(items=[sbs[0]])\n",
    "print(sbs[0].sbs[0].tag, sbs[0].sbs[1].tag)\n",
    "flat_tokens = Serializer.serialize(New_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 第三部分：在序列尾部加入新的指定tokens作为prompt，让model接下去预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grasp prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要添加的tokens: [96, 97]\n",
      "对应的token名称: ['detectgrasp', 'grasp']\n",
      "添加prompt后的序列长度: 3409\n",
      "完整prompt序列的最后20个tokens: [41892, 41924, 41925, 41926, 41958, 41959, 41960, 43727, 43728, 43761, 43762, 43795, 43796, 43829, 43830, 45598, 45632, 45666, 96, 97]\n"
     ]
    }
   ],
   "source": [
    "scene_promt = encode_sequence(flat_tokens, token_mapping)[:-1]\n",
    "print(len(scene_promt),scene_promt[-10:])\n",
    "\n",
    "# 指定要添加到序列尾部的tokens作为prompt\n",
    "# 这里可以根据需要修改，例如添加特定的命令tokens\n",
    "additional_tokens = [\n",
    "    token_mapping['detectgrasp'],  # 检测抓取命令\n",
    "    token_mapping['grasp'],         # 抓取命令\n",
    "    #token_mapping['object24']\n",
    "]\n",
    "\n",
    "print(f\"要添加的tokens: {additional_tokens}\")\n",
    "print(f\"对应的token名称: {[k for k, v in token_mapping.items() if v in additional_tokens]}\")\n",
    "\n",
    "# 将新的tokens添加到序列尾部\n",
    "prompt_sequence = scene_promt + additional_tokens\n",
    "#prompt_sequence = scene_promt\n",
    "\n",
    "print(f\"添加prompt后的序列长度: {len(prompt_sequence)}\")\n",
    "print(f\"完整prompt序列的最后20个tokens: {prompt_sequence[-20:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = generate_amodal_sequence(flat_tokens,(img_h, img_w, img_d))\n",
    "tokens = tokens[:tokens.index(\"unlabel\")+1]\n",
    "prompt_sequence = encode_sequence(tokens, token_mapping)\n",
    "#print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入张量形状: torch.Size([2, 568])\n",
      "原始序列长度: 568\n"
     ]
    }
   ],
   "source": [
    "# 准备输入张量\n",
    "def prepare_input_from_tokens(token_ids, max_length=None):\n",
    "    \"\"\"从token ID列表准备输入\"\"\"\n",
    "    if not token_ids:\n",
    "        raise ValueError(\"提供的token ID列表为空\")\n",
    "    \n",
    "    # 转换为张量\n",
    "    input_ids = torch.tensor([token_ids], dtype=torch.long)\n",
    "    \n",
    "    # 如果需要，进行截断\n",
    "    if max_length and input_ids.size(1) > max_length:\n",
    "        input_ids = input_ids[:, -max_length:]\n",
    "    \n",
    "    return input_ids\n",
    "\n",
    "# 准备输入\n",
    "input_ids = prepare_input_from_tokens(prompt_sequence, config.model.block_size)\n",
    "input_ids = input_ids.repeat(2,1)\n",
    "original_length = input_ids.size(1)\n",
    "\n",
    "print(f\"输入张量形状: {input_ids.shape}\")\n",
    "print(f\"原始序列长度: {original_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成配置: {'max_new_tokens': 5000, 'temperature': 0.8999999999999999, 'do_sample': True, 'top_k': None, 'eos_token_id': 98}\n"
     ]
    }
   ],
   "source": [
    "# 配置生成参数\n",
    "generation_config = {\n",
    "    'max_new_tokens': max_new_tokens+3000,\n",
    "    'temperature': temperature*3,\n",
    "    'do_sample': do_sample,\n",
    "    'top_k': top_k,\n",
    "    'eos_token_id': token_mapping.get('end', None)\n",
    "}\n",
    "\n",
    "print(f\"生成配置: {generation_config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始生成...\n",
      "输入长度: torch.Size([2, 568])\n",
      "生成完成，耗时: 204.77秒\n",
      "生成的序列长度: 5568 tokens. torch.Size([2, 5568, 1])\n"
     ]
    }
   ],
   "source": [
    "# 执行生成\n",
    "def generate_with_model(model_engine, input_ids, generation_config):\n",
    "    \"\"\"使用模型生成序列\"\"\"\n",
    "    # 将输入移动到正确的设备\n",
    "    if hasattr(model_engine, 'local_rank') and model_engine.local_rank is not None:\n",
    "        device = f'cuda:{model_engine.local_rank}'\n",
    "    else:\n",
    "        # 回退：从模型参数获取设备\n",
    "        device = next(model_engine.module.parameters()).device\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    \n",
    "    # 将模型设置为评估模式\n",
    "    model_engine.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 生成序列\n",
    "        if hasattr(model_engine.module, 'generate'):\n",
    "            generated = model_engine.module.generate(\n",
    "                idx=input_ids,\n",
    "                max_new_tokens=generation_config.get('max_new_tokens', 50),\n",
    "                temperature=generation_config.get('temperature', 1.0),\n",
    "                do_sample=generation_config.get('do_sample', True),\n",
    "                top_k=generation_config.get('top_k', None),\n",
    "                end_token=generation_config.get('eos_token_id', None)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"模型没有generate方法\")\n",
    "    \n",
    "    return generated\n",
    "\n",
    "print(\"开始生成...\")\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"输入长度:\",input_ids.size())\n",
    "# 执行生成\n",
    "generated = generate_with_model(model_engine, input_ids, generation_config)\n",
    "\n",
    "generation_time = time.time() - start_time\n",
    "\n",
    "print(f\"生成完成，耗时: {generation_time:.2f}秒\")\n",
    "print(f\"生成的序列长度: {generated.size(1)} tokens. {generated.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始可视化tokens ===\n",
      "正在转换token ids到序列...\n",
      "解码得到的tokens数量: 5568\n",
      "前10个tokens: ['scene', 'incomplete', (2, 24, 5), (3, 27, 6), (4, 23, 5), (4, 28, 6), (4, 29, 6), (4, 30, 1), (4, 30, 5), (5, 23, 5)]\n",
      "ParseError: Unexpected token 'unknow' after parsing SEQ at position 3127\n",
      "解析成功，序列包含 3 个项目\n",
      "体素信息: dims=(80, 54, 34), bbox_min=[-0.3 -0.2  0. ], voxel_size=0.0075\n",
      "正在按类别提取点云...\n",
      "Scene SB 'incomplete': 564 个点\n",
      "Amodal SB 'unlabel': 2157 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "GRASP 'incomplete': 3 个点\n",
      "已保存点云: output/tokens_visual/0/scene/incomplete.ply (564 个点)\n",
      "已保存点云: output/tokens_visual/0/scene/merged_scene.ply (564 个点)\n",
      "合并scene点云: 564 个点\n",
      "已保存点云: output/tokens_visual/0/amodal/unlabel.ply (2157 个点)\n",
      "已保存点云: output/tokens_visual/0/amodal/merged_amodal.ply (2157 个点)\n",
      "合并amodal点云: 2157 个点\n",
      "unseg 类别没有点云\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_1.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_2.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_3.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_4.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_5.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_6.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_7.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_8.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_9.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_10.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_11.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_12.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_13.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_14.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_15.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_16.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_17.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_18.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_19.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_20.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_21.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_22.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_23.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_24.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_25.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_26.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_27.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_28.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_29.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_30.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_31.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_32.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_33.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_34.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_35.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_36.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_37.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_38.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_39.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_40.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_41.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_42.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_43.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_44.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_45.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_46.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_47.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_48.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_49.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_50.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_51.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_52.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_53.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_54.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_55.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_56.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_57.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_58.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_59.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_60.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_61.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_62.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_63.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_64.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_65.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_66.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_67.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_68.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_69.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_70.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_71.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_72.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_73.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_74.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_75.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_76.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_77.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_78.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/incomplete_79.ply (3 个点)\n",
      "已保存点云: output/tokens_visual/0/grasp/merged_grasp.ply (240 个点)\n",
      "合并grasp点云: 240 个点\n",
      "已生成并保存 80 个抓取mesh，目录: output/tokens_visual/0/grasp_meshes\n",
      "tokens可视化完成，结果保存在: output/tokens_visual/0\n",
      "=== 开始可视化tokens ===\n",
      "正在转换token ids到序列...\n",
      "解码得到的tokens数量: 5568\n",
      "前10个tokens: ['scene', 'incomplete', (2, 24, 5), (3, 27, 6), (4, 23, 5), (4, 28, 6), (4, 29, 6), (4, 30, 1), (4, 30, 5), (5, 23, 5)]\n",
      "ParseError: Expected 'endamodal', got 'detectgrasp' at position 809\n",
      "解析成功，序列包含 1 个项目\n",
      "体素信息: dims=(80, 54, 34), bbox_min=[-0.3 -0.2  0. ], voxel_size=0.0075\n",
      "正在按类别提取点云...\n",
      "Scene SB 'incomplete': 564 个点\n",
      "已保存点云: output/tokens_visual/1/scene/incomplete.ply (564 个点)\n",
      "已保存点云: output/tokens_visual/1/scene/merged_scene.ply (564 个点)\n",
      "合并scene点云: 564 个点\n",
      "amodal 类别没有点云\n",
      "unseg 类别没有点云\n",
      "grasp 类别没有点云\n",
      "未生成任何抓取mesh。\n",
      "tokens可视化完成，结果保存在: output/tokens_visual/1\n"
     ]
    }
   ],
   "source": [
    "from extract_sample_and_export import visualize_tokens\n",
    "\n",
    "all_scene  = generated.squeeze().detach().cpu()\n",
    "all_scene[:,-1] = token_mapping.get('end', None)\n",
    "for i in range(all_scene.size(0)):\n",
    "    visualize_tokens(all_scene[i], token_mapping, volume_dims =(img_h, img_w, img_d), bbox_min = np.array([-0.3, -0.2, 0]), voxel_size = 0.0075, output_dir = f'./output/tokens_visual/{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scene', 'incomplete', (2, 24, 5), (3, 27, 6), (4, 23, 5), (4, 28, 6), (4, 29, 6), (4, 30, 1), (4, 30, 5), (5, 23, 5), (5, 24, 6), (5, 26, 7), (5, 27, 7), (5, 29, 6), (5, 30, 3), (5, 30, 4), (6, 23, 5), (6, 27, 7), (6, 29, 6), (7, 23, 2), (7, 23, 3), (7, 23, 4), (7, 24, 6), (7, 25, 6), (7, 29, 6), (8, 24, 1), (8, 24, 2), (8, 24, 3), (8, 24, 4), (8, 24, 5), (8, 26, 6), (8, 28, 6), (8, 29, 6), (8, 30, 2), (8, 30, 3), (8, 30, 4), (9, 25, 1), (9, 25, 2), (9, 25, 3), (9, 25, 4), (9, 25, 5), (9, 26, 1), (9, 26, 5), (9, 28, 1), (9, 28, 5), (9, 29, 2), (9, 29, 4), (10, 27, 2), (10, 27, 3), (10, 28, 3), (10, 28, 4), (40, 15, 6), (41, 14, 6), (41, 15, 6), (41, 16, 6), (41, 18, 5), (41, 44, 4), (42, 14, 6), (42, 16, 6), (42, 17, 6), (42, 18, 6), (42, 19, 2), (42, 19, 3), (42, 19, 4), (42, 47, 5), (43, 12, 5), (43, 13, 6), (43, 15, 6), (43, 16, 6), (43, 17, 6), (43, 18, 6), (43, 19, 1), (43, 19, 2), (43, 19, 4), (43, 19, 5), (43, 42, 5), (43, 43, 6), (43, 44, 6), (43, 45, 6), (43, 46, 6), (43, 47, 6), (43, 48, 6), (44, 13, 6), (44, 15, 6), (44, 16, 6), (44, 17, 6), (44, 18, 5), (44, 18, 6), (44, 19, 2), (44, 19, 3), (44, 19, 4), (44, 42, 6), (44, 43, 6), (44, 44, 6), (44, 45, 6), (44, 48, 6), (44, 49, 6), (45, 10, 4), (45, 13, 6), (45, 15, 6), (45, 16, 6), (45, 18, 1), (45, 18, 3), (45, 18, 4), (45, 18, 5), (45, 40, 5), (45, 41, 6), (45, 42, 6), (45, 43, 6), (45, 44, 6), (45, 45, 6), (45, 46, 7), (45, 48, 7), (46, 12, 6), (46, 15, 6), (46, 16, 6), (46, 18, 2), (46, 18, 3), (46, 18, 4), (46, 41, 6), (46, 42, 6), (46, 44, 6), (46, 45, 6), (46, 46, 7), (46, 47, 7), (46, 48, 7), (47, 12, 6), (47, 13, 6), (47, 14, 6), (47, 15, 6), (47, 16, 5), (47, 17, 4), (47, 17, 5), (47, 18, 3), (47, 39, 5), (47, 40, 6), (47, 43, 6), (47, 44, 6), (47, 45, 6), (47, 46, 6), (47, 48, 7), (47, 49, 7), (47, 50, 6), (47, 51, 6), (48, 9, 4), (48, 10, 5), (48, 11, 5), (48, 12, 6), (48, 13, 5), (48, 13, 6), (48, 14, 6), (48, 15, 5), (48, 16, 5), (48, 17, 1), (48, 17, 4), (48, 38, 5), (48, 41, 6), (48, 43, 0), (48, 43, 6), (48, 46, 6), (48, 47, 6), (48, 48, 6), (48, 48, 7), (48, 49, 6), (48, 49, 7), (48, 51, 3), (48, 51, 6), (48, 52, 4), (48, 52, 5), (49, 9, 5), (49, 10, 5), (49, 11, 5), (49, 12, 5), (49, 15, 5), (49, 16, 0), (49, 16, 3), (49, 16, 4), (49, 16, 5), (49, 17, 2), (49, 17, 3), (49, 38, 5), (49, 40, 6), (49, 41, 6), (49, 43, 6), (49, 44, 6), (49, 45, 6), (49, 46, 6), (49, 47, 6), (49, 48, 6), (49, 49, 6), (49, 50, 6), (50, 7, 4), (50, 9, 5), (50, 10, 5), (50, 11, 5), (50, 12, 5), (50, 13, 5), (50, 14, 5), (50, 15, 5), (50, 16, 3), (50, 16, 4), (50, 39, 6), (50, 40, 6), (50, 43, 6), (50, 44, 6), (50, 46, 6), (50, 47, 6), (50, 48, 6), (50, 49, 6), (50, 50, 6), (50, 51, 6), (51, 8, 5), (51, 9, 5), (51, 10, 5), (51, 11, 5), (51, 12, 5), (51, 13, 5), (51, 14, 5), (51, 15, 0), (51, 15, 4), (51, 16, 2), (51, 16, 3), (51, 36, 5), (51, 37, 6), (51, 38, 6), (51, 39, 6), (51, 40, 0), (51, 40, 6), (51, 41, 6), (51, 42, 6), (51, 43, 6), (51, 44, 0), (51, 45, 6), (51, 46, 6), (51, 48, 6), (51, 49, 6), (51, 50, 6), (51, 51, 5), (51, 52, 3), (52, 7, 4), (52, 8, 5), (52, 9, 5), (52, 10, 5), (52, 11, 5), (52, 12, 5), (52, 13, 4), (52, 13, 5), (52, 14, 4), (52, 15, 1), (52, 15, 2), (52, 15, 3), (52, 15, 4), (52, 34, 4), (52, 35, 4), (52, 36, 6), (52, 37, 6), (52, 38, 6), (52, 39, 6), (52, 40, 6), (52, 41, 6), (52, 42, 6), (52, 44, 6), (52, 45, 6), (52, 46, 6), (52, 47, 6), (52, 48, 6), (52, 51, 2), (52, 51, 3), (52, 51, 4), (53, 6, 4), (53, 7, 4), (53, 8, 4), (53, 9, 4), (53, 9, 5), (53, 10, 5), (53, 12, 4), (53, 13, 4), (53, 14, 0), (53, 14, 3), (53, 14, 4), (53, 32, 5), (53, 33, 5), (53, 35, 6), (53, 36, 6), (53, 37, 6), (53, 38, 6), (53, 39, 6), (53, 40, 0), (53, 42, 6), (53, 43, 6), (53, 44, 6), (53, 46, 6), (53, 47, 6), (53, 48, 5), (53, 48, 6), (53, 49, 2), (53, 49, 3), (53, 49, 4), (54, 5, 4), (54, 6, 4), (54, 7, 4), (54, 8, 4), (54, 11, 4), (54, 13, 4), (54, 14, 2), (54, 14, 3), (54, 31, 3), (54, 31, 4), (54, 32, 4), (54, 32, 5), (54, 34, 6), (54, 35, 6), (54, 36, 6), (54, 37, 6), (54, 38, 6), (54, 39, 6), (54, 40, 6), (54, 41, 6), (54, 42, 6), (54, 43, 6), (54, 44, 6), (54, 45, 6), (54, 46, 5), (54, 46, 6), (54, 47, 3), (54, 47, 4), (54, 48, 3), (54, 48, 4), (55, 5, 4), (55, 6, 4), (55, 7, 4), (55, 9, 4), (55, 10, 4), (55, 11, 4), (55, 13, 4), (55, 14, 1), (55, 14, 2), (55, 14, 3), (55, 32, 5), (55, 34, 5), (55, 34, 6), (55, 35, 6), (55, 36, 6), (55, 37, 6), (55, 40, 6), (55, 41, 6), (55, 42, 5), (55, 42, 6), (55, 43, 6), (55, 44, 5), (55, 44, 6), (55, 45, 5), (55, 46, 2), (55, 46, 4), (56, 3, 3), (56, 4, 3), (56, 5, 4), (56, 6, 3), (56, 7, 4), (56, 9, 4), (56, 10, 4), (56, 12, 3), (56, 13, 0), (56, 13, 1), (56, 13, 3), (56, 31, 4), (56, 32, 4), (56, 34, 6), (56, 35, 0), (56, 35, 6), (56, 37, 6), (56, 38, 6), (56, 39, 6), (56, 41, 6), (56, 42, 6), (56, 44, 1), (56, 44, 2), (56, 44, 4), (56, 44, 5), (56, 45, 3), (57, 3, 3), (57, 4, 3), (57, 5, 3), (57, 7, 3), (57, 7, 4), (57, 8, 4), (57, 9, 3), (57, 10, 4), (57, 11, 3), (57, 11, 4), (57, 12, 3), (57, 13, 1), (57, 31, 2), (57, 31, 4), (57, 33, 5), (57, 34, 5), (57, 34, 6), (57, 35, 6), (57, 36, 6), (57, 37, 6), (57, 39, 6), (57, 40, 6), (57, 41, 5), (57, 41, 6), (57, 42, 4), (57, 42, 5), (58, 1, 2), (58, 2, 2), (58, 3, 3), (58, 4, 3), (58, 5, 3), (58, 6, 3), (58, 7, 3), (58, 8, 3), (58, 10, 3), (58, 11, 3), (58, 12, 0), (58, 12, 1), (58, 12, 2), (58, 12, 3), (58, 32, 5), (58, 35, 5), (58, 35, 6), (58, 36, 5), (58, 36, 6), (58, 37, 6), (58, 39, 6), (58, 40, 5), (58, 42, 2), (58, 42, 4), (59, 1, 2), (59, 2, 2), (59, 3, 3), (59, 4, 2), (59, 4, 3), (59, 5, 2), (59, 5, 3), (59, 6, 3), (59, 7, 3), (59, 8, 3), (59, 9, 3), (59, 10, 3), (59, 12, 1), (59, 12, 2), (59, 30, 3), (59, 31, 3), (59, 32, 5), (59, 33, 5), (59, 34, 5), (59, 35, 5), (59, 37, 5), (59, 37, 6), (59, 38, 5), (59, 38, 6), (59, 39, 6), (59, 40, 5), (59, 41, 2), (60, 2, 2), (60, 4, 2), (60, 6, 2), (60, 8, 3), (60, 10, 3), (60, 11, 0), (60, 11, 1), (60, 29, 3), (60, 30, 4), (60, 32, 4), (60, 32, 5), (60, 33, 4), (60, 33, 5), (60, 34, 4), (60, 34, 5), (60, 35, 4), (60, 35, 5), (60, 36, 5), (60, 37, 5), (60, 38, 5), (60, 39, 5), (60, 40, 3), (60, 40, 4), (61, 3, 2), (61, 4, 1), (61, 5, 2), (61, 6, 2), (61, 8, 2), (61, 9, 3), (61, 10, 3), (61, 11, 0), (61, 11, 1), (61, 11, 2), (61, 28, 4), (61, 29, 4), (61, 30, 4), (61, 31, 4), (61, 32, 4), (61, 32, 5), (61, 33, 4), (61, 34, 1), (61, 34, 2), (61, 34, 4), (61, 35, 0), (61, 35, 1), (61, 35, 3), (61, 36, 0), (61, 36, 1), (61, 36, 2), (61, 36, 4), (61, 36, 5), (61, 37, 3), (61, 37, 5), (61, 38, 4), (61, 38, 5), (61, 39, 2), (61, 39, 4), (61, 39, 5), (62, 5, 1), (62, 6, 1), (62, 6, 2), (62, 9, 2), (62, 10, 0), (62, 10, 1), (62, 10, 2), (62, 28, 1), (62, 28, 4), (62, 30, 4), (62, 32, 4), (62, 33, 1), (62, 33, 3), (62, 33, 4), (62, 34, 1), (62, 37, 2), (62, 37, 4), (62, 38, 3), (62, 38, 4), (63, 5, 1), (63, 6, 1), (63, 8, 1), (63, 8, 2), (63, 9, 2), (63, 10, 0), (63, 10, 1), (63, 10, 2), (63, 29, 4), (63, 31, 4), (63, 32, 3), (64, 7, 1), (64, 8, 1), (64, 9, 1), (64, 10, 0), (64, 29, 4), (64, 30, 4), (64, 31, 3), (64, 32, 2), (64, 32, 3), (65, 8, 1), (65, 9, 1), (65, 30, 1), (65, 30, 4), (65, 31, 3), (65, 31, 4), (65, 32, 3), (65, 33, 2), (66, 31, 3), (66, 32, 2), (66, 33, 1), (66, 33, 2), 'amodal', 'unlabel', (2, 24, 2), (2, 24, 3), (2, 24, 4), (2, 24, 5), (2, 25, 1), (2, 25, 2), (2, 25, 3), (2, 25, 4), (2, 25, 5), (2, 26, 1), (2, 26, 2), (2, 26, 3), (2, 26, 4), (2, 26, 5), (2, 27, 1), (2, 27, 2), (2, 27, 3), (2, 27, 4), (2, 27, 5), (2, 28, 1), (2, 28, 2), (2, 28, 3), (2, 28, 4), (3, 22, 1), (3, 22, 2), (3, 22, 3), (3, 22, 4), (3, 22, 5), (3, 23, 1), (3, 23, 2), (3, 23, 3), (3, 23, 4), (3, 23, 5), (3, 24, 0), (3, 24, 1), (3, 24, 2), (3, 24, 3), (3, 24, 4), (3, 24, 5), (3, 24, 6), (3, 25, 0), (3, 25, 1), (3, 25, 5), (3, 25, 6), (3, 26, 0), (3, 26, 1), (3, 26, 5), (3, 26, 6), (3, 27, 0), (3, 27, 1), (3, 27, 4), (3, 27, 5), (3, 27, 6), (3, 28, 0), (3, 28, 1), (3, 28, 2), (3, 28, 3), (3, 28, 4), (3, 28, 5), (3, 28, 6), (3, 29, 1), (3, 29, 2), (3, 29, 3), (3, 29, 4), (3, 29, 5), (4, 21, 2), (4, 21, 3), (4, 21, 4), (4, 22, 1), (4, 22, 2), (4, 22, 3), (4, 22, 4), (4, 22, 5), (4, 23, 0), (4, 23, 1), (4, 23, 5), (4, 23, 6), (4, 24, 0), (4, 24, 6), (4, 25, 0), (4, 25, 6), (4, 25, 7), (4, 26, 0), (4, 26, 6), (4, 26, 7), (4, 27, 0), (4, 27, 6), (4, 28, 0), (4, 28, 1), (4, 28, 5), (4, 28, 6), (4, 29, 0), (4, 29, 1), (4, 29, 2), (4, 29, 3), (4, 29, 4), (4, 29, 5), (4, 29, 6), (4, 30, 1), (4, 30, 2), (4, 30, 3), (4, 30, 4), (4, 30, 5), (5, 21, 1), (5, 21, 2), (5, 21, 3), (5, 21, 4), (5, 22, 0), (5, 22, 1), (5, 22, 2), (5, 22, 4), (5, 22, 5), (5, 23, 0), (5, 23, 5), (5, 23, 6), (5, 24, 0), (5, 24, 6), (5, 25, 0), (5, 25, 6), (5, 25, 7), (5, 26, 0), (5, 26, 6), (5, 26, 7), (5, 27, 0), (5, 27, 6), (5, 27, 7), (5, 28, 0), (5, 28, 6), (5, 29, 0), (5, 29, 1), (5, 29, 5), (5, 29, 6), (5, 30, 1), (5, 30, 2), (5, 30, 3), (5, 30, 4), (5, 30, 5), (6, 21, 2), (6, 21, 3), (6, 21, 4), (6, 22, 0), (6, 22, 1), (6, 22, 2), (6, 22, 3), (6, 22, 4), (6, 22, 5), (6, 23, 0), (6, 23, 5), (6, 23, 6), (6, 24, 0), (6, 24, 5), (6, 24, 6), (6, 25, 0), (6, 25, 6), (6, 26, 0), (6, 26, 6), (6, 26, 7), (6, 27, 0), (6, 27, 6), (6, 27, 7), (6, 28, 0), (6, 28, 6), (6, 29, 0), (6, 29, 1), (6, 29, 5), (6, 29, 6), (6, 30, 1), (6, 30, 2), (6, 30, 3), (6, 30, 4), (6, 30, 5), (7, 22, 1), (7, 22, 2), (7, 22, 3), (7, 22, 4), (7, 22, 5), (7, 23, 0), (7, 23, 1), (7, 23, 4), (7, 23, 5), (7, 24, 0), (7, 24, 1), (7, 24, 5), (7, 24, 6), (7, 25, 0), (7, 25, 5), (7, 25, 6), (7, 26, 0), (7, 26, 6), (7, 27, 0), (7, 27, 6), (7, 28, 0), (7, 28, 1), (7, 28, 5), (7, 28, 6), (7, 29, 1), (7, 29, 2), (7, 29, 3), (7, 29, 4), (7, 29, 5), (7, 29, 6), (7, 30, 1), (7, 30, 2), (7, 30, 3), (7, 30, 4), (7, 30, 5), (8, 22, 2), (8, 22, 3), (8, 22, 4), (8, 23, 1), (8, 23, 2), (8, 23, 3), (8, 23, 4), (8, 23, 5), (8, 24, 0), (8, 24, 1), (8, 24, 2), (8, 24, 3), (8, 24, 4), (8, 24, 5), (8, 25, 0), (8, 25, 1), (8, 25, 4), (8, 25, 5), (8, 25, 6), (8, 26, 0), (8, 26, 1), (8, 26, 5), (8, 26, 6), (8, 27, 0), (8, 27, 1), (8, 27, 5), (8, 27, 6), (8, 28, 0), (8, 28, 1), (8, 28, 2), (8, 28, 3), (8, 28, 4), (8, 28, 5), (8, 28, 6), (8, 29, 1), (8, 29, 2), (8, 29, 3), (8, 29, 4), (8, 29, 5), (9, 24, 2), (9, 24, 3), (9, 24, 4), (9, 25, 1), (9, 25, 2), (9, 25, 3), (9, 25, 4), (9, 25, 5), (9, 26, 1), (9, 26, 2), (9, 26, 3), (9, 26, 4), (9, 26, 5), (9, 27, 1), (9, 27, 2), (9, 27, 3), (9, 27, 4), (9, 27, 5), (9, 28, 1), (9, 28, 2), (9, 28, 3), (9, 28, 4), (9, 28, 5), (9, 29, 2), (9, 29, 3), (9, 29, 4), 'detectgrasp', 'grasp', 'incomplete', (2, 26, 5), (5, 23, 7), (10, 22, 6), 'grasp', 'incomplete', (2, 26, 5), (5, 23, 8), (10, 22, 6), 'grasp', 'incomplete', (2, 26, 5), (7, 6, 7), (8, 33, 4), 'grasp', 'incomplete', (2, 26, 5), (7, 28, 8), (13, 28, 7), 'grasp', 'incomplete', (2, 26, 5), (7, 28, 8), (13, 28, 7), 'grasp', 'incomplete', (3, 22, 5), (3, 27, 9), (6, 33, 8), 'grasp', 'incomplete', (2, 26, 5), (5, 23, 8), (10, 21, 7), 'grasp', 'incomplete', (2, 26, 5), (7, 26, 9), (12, 25, 7), 'grasp', 'incomplete', (2, 26, 5), (5, 23, 7), (10, 22, 6), 'grasp', 'incomplete', (2, 26, 5), (7, 28, 8), (13, 28, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 4), (4, 31, 7), (9, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (7, 28, 8), (13, 28, 7), 'grasp', 'incomplete', (2, 26, 5), (4, 25, 7), (9, 25, 6), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (5, 28, 6), (6, 32, 7), (7, 29, 3), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (5, 23, 8), (10, 21, 6), 'grasp', 'incomplete', (2, 26, 5), (5, 23, 7), (10, 22, 6), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (5, 23, 8), (10, 21, 7), 'grasp', 'incomplete', (2, 26, 5), (7, 28, 8), (13, 28, 7), 'grasp', 'incomplete', (2, 26, 5), (7, 28, 8), (13, 28, 7), 'grasp', 'incomplete', (2, 29, 3), (8, 30, 4), (14, 26, 4), 'grasp', 'incomplete', (2, 26, 5), (7, 28, 8), (13, 28, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (0, 27, 4), (5, 26, 9), (11, 26, 8), 'grasp', 'incomplete', (2, 26, 5), (7, 28, 8), (13, 28, 7), 'grasp', 'incomplete', (5, 28, 6), (6, 33, 6), (7, 29, 2), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (1, 23, 3), (5, 27, 6), (11, 31, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (5, 23, 8), (10, 21, 7), 'grasp', 'incomplete', (2, 28, 5), (4, 23, 9), (9, 22, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'grasp', 'incomplete', (2, 26, 5), (2, 27, 8), (6, 30, 7), 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow', 'unknow']\n"
     ]
    }
   ],
   "source": [
    "print(decode_sequence(generated[1].cpu().squeeze().numpy().tolist(),token_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整序列（原始 + prompt + 生成）\n",
    "full_sequence = input_ids[0].cpu().numpy().tolist() + decoded_tokens\n",
    "\n",
    "print(f\"完整序列长度: {len(full_sequence)}\")\n",
    "print(f\"完整序列的最后30个tokens: {full_sequence[-30:]}\")\n",
    "\n",
    "# 保存结果\n",
    "result = {\n",
    "    'original_sequence_length': len(token_sequence),\n",
    "    'prompt_tokens': additional_tokens,\n",
    "    'input_length': original_length,\n",
    "    'generated_tokens': decoded_tokens,\n",
    "    'generated_token_names': decoded_names,\n",
    "    'total_length': len(full_sequence),\n",
    "    'generation_time': generation_time,\n",
    "    'generation_config': generation_config,\n",
    "    'full_sequence': full_sequence\n",
    "}\n",
    "\n",
    "print(\"\\n=== 生成结果总结 ===\")\n",
    "print(f\"原始序列长度: {result['original_sequence_length']}\")\n",
    "print(f\"添加的prompt tokens: {result['prompt_tokens']}\")\n",
    "print(f\"输入长度: {result['input_length']}\")\n",
    "print(f\"生成的新tokens: {result['generated_tokens']}\")\n",
    "print(f\"生成时间: {result['generation_time']:.2f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 可选：可视化生成结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选：使用可视化功能（如果extract_sample_and_export模块可用）\n",
    "try:\n",
    "    sys.path.append('../')\n",
    "    from extract_sample_and_export import visualize_tokens\n",
    "    \n",
    "    # 设置可视化参数（根据实际情况调整）\n",
    "    volume_dims = (img_h, img_w, img_d)\n",
    "    bbox_min = np.array([-0.3, -0.2, 0])  # 根据实际情况调整\n",
    "    voxel_size = 0.0075  # 根据实际情况调整\n",
    "    \n",
    "    # 可视化完整序列\n",
    "    output_dir = \"./output/generation_visual/notebook_result\"\n",
    "    \n",
    "    visualize_tokens(\n",
    "        tokens=full_sequence,\n",
    "        token_mapping=token_mapping,\n",
    "        volume_dims=volume_dims,\n",
    "        bbox_min=bbox_min,\n",
    "        voxel_size=voxel_size,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    print(f\"可视化结果保存到: {output_dir}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"可视化模块不可用，跳过可视化步骤\")\n",
    "except Exception as e:\n",
    "    print(f\"可视化过程中出错: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 保存结果到文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果到JSON文件\n",
    "output_file = \"generation_result.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"结果已保存到: {output_file}\")\n",
    "\n",
    "# 同时保存为.pth文件以便后续使用\n",
    "torch.save({\n",
    "    'generated_sequence': full_sequence,\n",
    "    'metadata': result\n",
    "}, \"generation_result.pth\")\n",
    "\n",
    "print(\"结果也已保存为generation_result.pth\")\n",
    "print(\"\\n生成完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
